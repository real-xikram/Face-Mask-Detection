{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries and modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xikram/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xikram/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xikram/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xikram/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xikram/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xikram/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D , Input , ZeroPadding2D , BatchNormalization , Activation , MaxPooling2D , Flatten , Dense , Dropout\n",
    "from keras.models import Model , load_model\n",
    "from keras.callbacks import TensorBoard , ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import imutils\n",
    "import numpy as np\n",
    "import webp\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xikram/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xikram/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xikram/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xikram/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xikram/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xikram/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/xikram/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xikram/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/xikram/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "                                Conv2D( 100 , ( 3 , 3 ) , activation= 'relu' , input_shape = (150 , 150 , 3)),\n",
    "                                MaxPooling2D( 2 , 2 ) ,\n",
    "                                Conv2D( 100 , ( 3 , 3 ) , activation= 'relu'),\n",
    "                                MaxPooling2D( 2 , 2 ),\n",
    "                                Flatten(),\n",
    "                                Dropout( 0.5 ),\n",
    "                                Dense( 50 , activation= 'relu'),\n",
    "                                Dense( 2 , activation='softmax')\n",
    "                                ])\n",
    "model.compile( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data Generation / Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1315 images belonging to 2 classes.\n",
      "Found 194 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = \"./Dataset/train\"\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                                               rotation_range = 40,\n",
    "                                                               width_shift_range = 0.2,\n",
    "                                                               height_shift_range = 0.2,\n",
    "                                                               shear_range = 0.2,\n",
    "                                                               zoom_range= 0.2,\n",
    "                                                               horizontal_flip=True , \n",
    "                                                               fill_mode = 'nearest'\n",
    "                                                                )\n",
    "train_generator = train_datagen.flow_from_directory( TRAINING_DIR , batch_size = 10 , target_size = (150 , 150))\n",
    "\n",
    "VALIDATION_DIR = \"./Dataset/test\"\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR , batch_size = 10 , target_size = (150 , 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise a callback checkpoint for the best model after each epoch while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint( 'model2-{epoch:03d}.h5' , monitor='val_loss' , verbose = 1 , save_best_only = True , mode = 'auto' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "130/130 [==============================] - 103s 790ms/step - loss: 0.1855 - acc: 0.9277 - val_loss: 0.0483 - val_acc: 0.9848\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04830, saving model to model2-001.h5\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 106s 816ms/step - loss: 0.1999 - acc: 0.9269 - val_loss: 0.1321 - val_acc: 0.9220\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04830\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 100s 771ms/step - loss: 0.1655 - acc: 0.9346 - val_loss: 0.0267 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04830 to 0.02666, saving model to model2-003.h5\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 100s 768ms/step - loss: 0.1595 - acc: 0.9400 - val_loss: 0.0356 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02666\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 100s 770ms/step - loss: 0.1382 - acc: 0.9500 - val_loss: 0.0676 - val_acc: 0.9734\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02666\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 100s 770ms/step - loss: 0.1452 - acc: 0.9485 - val_loss: 0.0402 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02666\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 100s 767ms/step - loss: 0.1921 - acc: 0.9354 - val_loss: 0.0350 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02666\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 100s 771ms/step - loss: 0.1476 - acc: 0.9423 - val_loss: 0.0294 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02666\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 100s 770ms/step - loss: 0.1446 - acc: 0.9431 - val_loss: 0.0220 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02666 to 0.02203, saving model to model2-009.h5\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 101s 774ms/step - loss: 0.1335 - acc: 0.9446 - val_loss: 0.0223 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02203\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator , epochs=  10 ,steps_per_epoch=130,validation_data= validation_generator  ,validation_steps=190, callbacks= [checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
